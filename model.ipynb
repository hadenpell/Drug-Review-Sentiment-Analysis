{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from seaborn import barplot\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't include \"Unnamed:0\" column. Separate features and outcome.\n",
    "\n",
    "X_train = train.iloc[:, 1:5001]\n",
    "X_test = test.iloc[:, 1:5001]\n",
    "y_train = train['rating_class']\n",
    "y_test = test['rating_class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower Level Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [MultinomialNB(), LogisticRegression(), DecisionTreeClassifier(max_depth=100), RandomForestClassifier(max_depth=100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['MultinomialNB','LogisticRegression','DecisionTreeClassifier','RandomForestClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test low level models: Naive Bayes, DT, LogReg, RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "metrics=[]\n",
    "\n",
    "for m,m_name in zip(models,model_names):\n",
    "    \n",
    "    m = m.fit(X=X_train,y=y_train)\n",
    "    y_pred_train = m.predict(X_train)\n",
    "    y_pred_test = m.predict(X_test)\n",
    "    \n",
    "    #Train metrics\n",
    "    accuracy_train = m.score(X_train, y_train)\n",
    "    precision_train = precision_score(y_train,y_pred_train)\n",
    "    recall_train = recall_score(y_train,y_pred_train)\n",
    "    f1_train = f1_score(y_train,y_pred_train)\n",
    "    \n",
    "    #Test metrics\n",
    "    accuracy_test = m.score(X_test, y_test)\n",
    "    precision_test = precision_score(y_test,y_pred_test)\n",
    "    recall_test = recall_score(y_test,y_pred_test)\n",
    "    f1_test = f1_score(y_test,y_pred_test)\n",
    "    \n",
    "    params = {\n",
    "        'model': m_name\n",
    "    }\n",
    "        \n",
    "    metrics.append(params | {'acc_train': accuracy_train,'prec_train':precision_train,\n",
    "                            'recall_train':recall_train,'f1_train':f1_train,\n",
    "                            'acc_test':accuracy_test,'prec_test':precision_test,\n",
    "                            'recall_test':recall_test,'f1_test':f1_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>prec_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>prec_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.800421</td>\n",
       "      <td>0.802665</td>\n",
       "      <td>0.949055</td>\n",
       "      <td>0.869743</td>\n",
       "      <td>0.795010</td>\n",
       "      <td>0.796735</td>\n",
       "      <td>0.948544</td>\n",
       "      <td>0.866037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.851925</td>\n",
       "      <td>0.870411</td>\n",
       "      <td>0.927121</td>\n",
       "      <td>0.897871</td>\n",
       "      <td>0.839502</td>\n",
       "      <td>0.860979</td>\n",
       "      <td>0.918559</td>\n",
       "      <td>0.888837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.962375</td>\n",
       "      <td>0.949680</td>\n",
       "      <td>0.999361</td>\n",
       "      <td>0.973887</td>\n",
       "      <td>0.854650</td>\n",
       "      <td>0.871926</td>\n",
       "      <td>0.928277</td>\n",
       "      <td>0.899219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.973217</td>\n",
       "      <td>0.963308</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.981281</td>\n",
       "      <td>0.890314</td>\n",
       "      <td>0.873999</td>\n",
       "      <td>0.984981</td>\n",
       "      <td>0.926177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        acc_train  prec_train  recall_train  f1_train  \\\n",
       "model                                                                   \n",
       "MultinomialNB            0.800421    0.802665      0.949055  0.869743   \n",
       "LogisticRegression       0.851925    0.870411      0.927121  0.897871   \n",
       "DecisionTreeClassifier   0.962375    0.949680      0.999361  0.973887   \n",
       "RandomForestClassifier   0.973217    0.963308      0.999938  0.981281   \n",
       "\n",
       "                        acc_test  prec_test  recall_test   f1_test  \n",
       "model                                                               \n",
       "MultinomialNB           0.795010   0.796735     0.948544  0.866037  \n",
       "LogisticRegression      0.839502   0.860979     0.918559  0.888837  \n",
       "DecisionTreeClassifier  0.854650   0.871926     0.928277  0.899219  \n",
       "RandomForestClassifier  0.890314   0.873999     0.984981  0.926177  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics).set_index('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Multinomial Naive Bayes\n",
    "# Hyperparameter: Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultinomialNB(),\n",
       "             param_grid={'alpha': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"alpha\": np.arange(0.1,1.1,0.1)}\n",
    "grid_search = GridSearchCV(MultinomialNB(), param_grid)\n",
    "grid_search.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'alpha': 0.1}\n",
      "Best cross-validation score:  0.7975660559471361\n",
      "Test set score:  0.7958332554094742\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "print(\"Test set score: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MultinomialNB(alpha=0.1).fit(X=X_train,y=y_train)\n",
    "y_pred_train = m.predict(X_train)\n",
    "y_pred_test = m.predict(X_test)\n",
    "\n",
    "#Train metrics\n",
    "accuracy_train = m.score(X_train, y_train)\n",
    "precision_train = precision_score(y_train,y_pred_train)\n",
    "recall_train = recall_score(y_train,y_pred_train)\n",
    "f1_train = f1_score(y_train,y_pred_train)\n",
    "\n",
    "#Test metrics\n",
    "accuracy_test = m.score(X_test, y_test)\n",
    "precision_test = precision_score(y_test,y_pred_test)\n",
    "recall_test = recall_score(y_test,y_pred_test)\n",
    "f1_test = f1_score(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7958332554094742, 0.7978725801726275, 0.947847504819019, 0.8664178647904559)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test accuracy:\", accuracy_test)\n",
    "print(\"Test precision:\", precision_test)\n",
    "print(\"Test recall:\", recall_test)\n",
    "print(\"Test F1:\", f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Decision Tree\n",
    "# Grid search was taking way too long. Decision Tree had used max_depth=100\n",
    "# to reduce complexity and time originally,\n",
    "# so we tried increasing it to 150. It performed better on both\n",
    "# test and train sets so we used this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=150).fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = dt.predict(X_train)\n",
    "y_pred_test = dt.predict(X_test)\n",
    "\n",
    "#Train metrics\n",
    "accuracy_train = dt.score(X_train, y_train)\n",
    "precision_train = precision_score(y_train,y_pred_train)\n",
    "recall_train = recall_score(y_train,y_pred_train)\n",
    "f1_train = f1_score(y_train,y_pred_train)\n",
    "\n",
    "#Test metrics\n",
    "accuracy_test = dt.score(X_test, y_test)\n",
    "precision_test = precision_score(y_test,y_pred_test)\n",
    "recall_test = recall_score(y_test,y_pred_test)\n",
    "f1_test = f1_score(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8647865197957771,\n",
       " 0.8921726903447558,\n",
       " 0.9173002784322125,\n",
       " 0.9045620148899097)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test accuracy:\", accuracy_test)\n",
    "print(\"Test precision:\", precision_test)\n",
    "print(\"Test recall:\", recall_test)\n",
    "print(\"Test F1:\", f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Logistic regression - No hyperparameter tuning was done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Random Forest\n",
    "rf = RandomForestClassifier(max_depth=150).fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = rf.predict(X_train)\n",
    "y_pred_test = rf.predict(X_test)\n",
    "\n",
    "#Train metrics\n",
    "accuracy_train = rf.score(X_train, y_train)\n",
    "precision_train = precision_score(y_train,y_pred_train)\n",
    "recall_train = recall_score(y_train,y_pred_train)\n",
    "f1_train = f1_score(y_train,y_pred_train)\n",
    "\n",
    "#Test metrics\n",
    "accuracy_test = rf.score(X_test, y_test)\n",
    "precision_test = precision_score(y_test,y_pred_test)\n",
    "recall_test = recall_score(y_test,y_pred_test)\n",
    "f1_test = f1_score(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9081745245086121\n",
      "Test precision: 0.8969508613938919\n",
      "Test recall: 0.9812861426429642\n",
      "Test F1: 0.9372251201800142\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy:\", accuracy_test)\n",
    "print(\"Test precision:\", precision_test)\n",
    "print(\"Test recall:\", recall_test)\n",
    "print(\"Test F1:\", f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
