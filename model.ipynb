{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from seaborn import barplot\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't include \"Unnamed:0\" column. Separate features and outcome.\n",
    "\n",
    "X_train = train.iloc[:, 1:5001]\n",
    "X_test = test.iloc[:, 1:5001]\n",
    "y_train = train['rating_class']\n",
    "y_test = test['rating_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower Level Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [MultinomialNB(), LogisticRegression(), DecisionTreeClassifier(max_depth=100), RandomForestClassifier(max_depth=100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['MultinomialNB','LogisticRegression','DecisionTreeClassifier','RandomForestClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test low level models: Naive Bayes, DT, LogReg, RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "metrics=[]\n",
    "\n",
    "for m,m_name in zip(models,model_names):\n",
    "    \n",
    "    m = m.fit(X=X_train,y=y_train)\n",
    "    y_pred_train = m.predict(X_train)\n",
    "    y_pred_test = m.predict(X_test)\n",
    "    \n",
    "    #Train metrics\n",
    "    accuracy_train = m.score(X_train, y_train)\n",
    "    precision_train = precision_score(y_train,y_pred_train)\n",
    "    recall_train = recall_score(y_train,y_pred_train)\n",
    "    f1_train = f1_score(y_train,y_pred_train)\n",
    "    \n",
    "    #Test metrics\n",
    "    accuracy_test = m.score(X_test, y_test)\n",
    "    precision_test = precision_score(y_test,y_pred_test)\n",
    "    recall_test = recall_score(y_test,y_pred_test)\n",
    "    f1_test = f1_score(y_test,y_pred_test)\n",
    "    \n",
    "    params = {\n",
    "        'model': m_name\n",
    "    }\n",
    "        \n",
    "    metrics.append(params | {'acc_train': accuracy_train,'prec_train':precision_train,\n",
    "                            'recall_train':recall_train,'f1_train':f1_train,\n",
    "                            'acc_test':accuracy_test,'prec_test':precision_test,\n",
    "                            'recall_test':recall_test,'f1_test':f1_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>prec_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>prec_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.800428</td>\n",
       "      <td>0.802703</td>\n",
       "      <td>0.948993</td>\n",
       "      <td>0.869739</td>\n",
       "      <td>0.795141</td>\n",
       "      <td>0.796767</td>\n",
       "      <td>0.948731</td>\n",
       "      <td>0.866134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.851563</td>\n",
       "      <td>0.870095</td>\n",
       "      <td>0.926970</td>\n",
       "      <td>0.897632</td>\n",
       "      <td>0.838810</td>\n",
       "      <td>0.860162</td>\n",
       "      <td>0.918585</td>\n",
       "      <td>0.888414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.960698</td>\n",
       "      <td>0.948178</td>\n",
       "      <td>0.998597</td>\n",
       "      <td>0.972735</td>\n",
       "      <td>0.854201</td>\n",
       "      <td>0.871886</td>\n",
       "      <td>0.927581</td>\n",
       "      <td>0.898871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.970879</td>\n",
       "      <td>0.960251</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.979680</td>\n",
       "      <td>0.888912</td>\n",
       "      <td>0.873117</td>\n",
       "      <td>0.983963</td>\n",
       "      <td>0.925232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        acc_train  prec_train  recall_train  f1_train  \\\n",
       "model                                                                   \n",
       "MultinomialNB            0.800428    0.802703      0.948993  0.869739   \n",
       "LogisticRegression       0.851563    0.870095      0.926970  0.897632   \n",
       "DecisionTreeClassifier   0.960698    0.948178      0.998597  0.972735   \n",
       "RandomForestClassifier   0.970879    0.960251      0.999911  0.979680   \n",
       "\n",
       "                        acc_test  prec_test  recall_test   f1_test  \n",
       "model                                                               \n",
       "MultinomialNB           0.795141   0.796767     0.948731  0.866134  \n",
       "LogisticRegression      0.838810   0.860162     0.918585  0.888414  \n",
       "DecisionTreeClassifier  0.854201   0.871886     0.927581  0.898871  \n",
       "RandomForestClassifier  0.888912   0.873117     0.983963  0.925232  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics).set_index('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
